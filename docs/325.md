# ML 的未来:无监督学习，强化学习，还是其他？

> 原文：<https://blog.paperspace.com/the-future-of-ml/>

在过去十年的大部分时间里，监督学习一直是大多数人工智能研究的焦点，但机器学习的未来可能取决于无监督学习方法。我与[约舒阿和萨米·本吉奥](https://en.wikipedia.org/wiki/Yoshua_Bengio)、[扬·勒村](https://en.wikipedia.org/wiki/Yann_LeCun)、[里奇·萨顿](https://en.wikipedia.org/wiki/Richard_S._Sutton)和[谢尔盖·莱文](https://people.eecs.berkeley.edu/~svlevine/)谈论了机器学习的未来，以及什么可能让我们的机器达到人类水平的智能。

约舒阿·本吉奥:

> 无监督引导的学习方法是第一个允许我们训练深度网络的方法。然后在 2010-2011 年左右，我们意识到我们不需要这些无监督的学习技术。我们可以训练非常深入的直接监督模型。然后，计算机视觉、语音识别、机器翻译等工业应用开始迅速出现。但这对人类水平的人工智能来说是不够的。人类不需要那么多监督。

萨米·本吉奥:

> 不仅仅是监督和不监督。中间有很多东西。有自我监督，有强化学习。有很多方法可以从你已经拥有的数据中获得廉价的监管。所以，它变成了一个更加复杂的空间。连接所有这些的是你如何表示数据，所以表示学习实际上变得越来越重要。

去年与 Yoshua 和 Geoffrey Hinton 分享图灵奖的 Yann Lecun 谈到了他对自我监督学习的押注。

**【yann lecun:**

> 由于你需要大量的标记数据，所以你今天可以应用深度学习的东西是有限的。只有当您能够收集这些数据并且能够正确标记它们时，它才是经济上可行的，而且这只适用于相对较少的应用程序。

> 如果你有很多平行文本，监督学习对于分类对象和图像或者从一种语言翻译到另一种语言非常有用。如果你收集了足够的数据，它对语音识别非常有用。

> 但是动物有一些学习的过程，来获得它们所拥有的关于世界的所有知识，这是机器所没有的。我的钱花在自我监督学习上，让机器通过观察来学习，或者在不需要那么多标记样本的情况下学习，或许通过观察积累足够的背景知识，某种常识就会出现。

> 想象一下，你给机器一个输入，比如一个视频剪辑。你屏蔽一段视频剪辑，然后让机器从它看到的内容中预测下一步会发生什么。

> 为了让机器训练自己做到这一点，它必须开发数据的某种表示。它必须明白有些物体是有生命的，有些是无生命的。无生命的物体有可预测的轨迹，其他的没有。所以，你用这种自我监督的方式，用成千上万的数据训练一个系统。你可以让这台机器观看的 YouTube 视频数量没有限制。它会从中提取出一些世界的表象。当你有一个特定的任务时，比如学习开车或识别特定的物体，你使用这种表示作为分类器的输入，然后训练这个分类器。

> 我们能在某个时候制造出和人类一样聪明的机器吗？答案是，当然，毫无疑问。这是时间问题。

Rich Sutton 谈到了他开创的无监督学习形式:强化学习。

**里奇·萨顿:**

> 我在寻找类似强化学习的东西，因为如果你学习心理学，强化是一个显而易见的想法。有两种基本类型。巴甫洛夫条件作用和工具性或操作性条件作用。

> 巴甫洛夫条件反射就像，按铃，然后给狗一块牛排。过了一会儿，刚按完铃，他就垂涎三尺，表示他期待牛排的到来。所以，这是一种预测学习。

> 然后是控制学习，控制学习被称为工具性条件反射或操作性条件反射，至少是这两个名字，在这里你改变你的行为来引起一些事情发生。在巴甫洛夫条件反射中，你的唾液分泌不会影响发生的事情。而标准的操作条件是，老鼠按下一根棒，然后得到一个食物球。按压杆的动作有助于获得奖励。

> 这就是强化学习的理念。这是模仿动物和人类一直在做的一件显而易见的事情。在监督学习中，反馈指导你应该做什么。在强化过程中，反馈是一种奖励，它只是评估你做了什么。所以，评估和指导是最根本的区别。

最后，Sergey Levine，世界上最杰出的机器学习和机器人交叉领域的研究人员之一，谈到了如何通过他在伯克利人工智能实验室工作的机器人将无监督学习带入现实世界。

谢尔盖·莱文:

> 我们希望从长远来看，我们的工作可以成为未来的垫脚石，在未来，世界上有许多联网的机器人，当他们不忙着做更有生产力的事情时，他们只会玩他们的环境和学习。

> 他们基本上会说，‘好吧，如果我目前没有工作任务，如果我的人类主人不想让我做任何特别的事情，我就用我的空闲时间来练习。“我会摆弄周围环境中的物品，更多地了解这个世界是如何运转的，并利用它来建立我的知识体系，这样当我后来被置于某个新的环境中时，希望我已经从过去的许多情况中学到了足够多的东西，可以在这个新的环境中做一些合理的事情。”这就是转移。和所有的学习系统一样，这种转移来自于丰富的经验。

> 所以，如果你有足够的广度，你见过足够多的变化，那么你就为任何事情做好了准备。这就是梦想。现在的现实是，这只是朝着这个方向迈出的第一步。现在，机器人学习一个特定的环境。它花几个小时玩一扇门，移动它，它可以打开那扇门。我们下一步想做的事情之一是扩大规模。在楼下的实验室里，我们有六个不同的机器人，所以也许我们让他们都玩不同种类的门，也许然后我们会看到，当我们给它一个新的门时，它实际上会推广到那个新的门，因为它看到了足够多的变化。

> 多样性是一般化和转移的关键，但我也认为从长远来看，在机器人学中，这不应该是一个问题，因为机器人存在于现实世界中，与我们存在的现实世界相同。现实世界迫使你多样化。你不能逃避它。

> 我们的工作假设是，如果我们建立了足够通用的算法，那么我们真正要做的就是，一旦完成，把它们放在机器人身上，这些机器人在真实的世界里做真实的事情，各种各样的经验将会来到机器人身上，因为它们和我们一样在真实的世界里。所以，机器人基本上想象可能发生的事情，然后试图找出如何让它发生。当然，想象可能发生的事情需要了解世界上哪些是现实情况，哪些不是现实情况。

> 我可以给自己定一个目标。我可以说我想让这个杯子悬浮起来。对我来说，这将是一个很难达到的目标，因为在这个宇宙中，这并不现实。但是如果我给自己设定一个目标，让这个杯子向左移动 5 厘米，这是我可以学习和练习的，这将教会我一些关于这个杯子的物理知识。

这篇文章改编自播客 [Eye on AI](https://www.eye-on.ai/) 第 30 集的后半部分。查看前半部分的[气候变化，中国和艾](https://blog.paperspace.com/climate-change-china-and-ai/)，在这里找到完整录制的[集，或者听下面的。](https://www.eye-on.ai/podcast-030)

[//html5-player.libsyn.com/embed/episode/id/12641138/height/50/theme/legacy/thumbnail/no/direction/backward/](//html5-player.libsyn.com/embed/episode/id/12641138/height/50/theme/legacy/thumbnail/no/direction/backward/)